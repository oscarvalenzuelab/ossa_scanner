import os
import json
import hashlib
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from .utils.os_detection import detect_os
from .utils.package_manager import list_packages, get_package_info
from .utils.downloader import download_source
from .utils.hash_calculator import calculate_file_hash
from .utils.swhid_calculator import calculate_swhid

class Scanner:
    def __init__(self, threads=4, output_dir="ossa_reports", temp_dir="/tmp/ossa_temp"):
        self.output_dir = output_dir
        self.temp_dir = temp_dir
        self.os_type = detect_os()
        self.threads = threads
        os.makedirs(self.temp_dir, exist_ok=True)

    def process_package(self, package):
        try:
            print(f"Processing package: {package}")
            package_info = get_package_info(self.os_type, package)
            source_files = download_source(self.os_type, package, self.temp_dir)
            self.save_package_report(package, package_info, source_files)
        except Exception as e:
            print(f"Error processing package {package}: {e}")

    def scan_packages(self):
        """
        Scans all packages in the repository and processes them in parallel.
        """
        print(f"Detected OS: {self.os_type}")
        print("Listing available packages...")
        packages = list_packages(self.os_type)
        with ThreadPoolExecutor(max_workers=self.threads) as executor:
            # Submit tasks for parallel processing
            future_to_package = {
                executor.submit(self.process_package, package): package
                for package in packages
            }

            for future in as_completed(future_to_package):
                package = future_to_package[future]
                try:
                    future.result()
                except Exception as e:
                    print(f"Exception occurred for package {package}: {e}")

    def save_package_report(self, package, package_info, source_files):
        # Generate report filename
        date_str = datetime.now().strftime("%Y%m%d")
        report_filename = f"ossa-{date_str}-{hash(package) % 10000}-{package}.json"
        report_path = os.path.join(self.output_dir, report_filename)

        if package_info.get("version") != "*":
            affected_versions = ["*.*", package_info.get("version")]
        else:
            affected_versions = ["*.*"]

        artifacts = []
        for source_file in source_files:
            artifact = {}

            # Clean up the artifact name
            artifact_name = os.path.basename(source_file)
            if "--" in artifact_name:
                artifact_name = artifact_name.split("--")[-1]
            artifact['url'] = "file://" + artifact_name

            file_hash = calculate_file_hash(source_file)
            artifact['hashes'] = file_hash

            # Extract source code directory in temp_dir
            # Only required if calculating SWHID
            source_dir = os.path.join(self.temp_dir, package)
            os.makedirs(source_dir, exist_ok=True)
            swhid = calculate_swhid(source_dir)
            artifact['swhid'] = swhid

            artifacts.append(artifact)

        purl_name = package_info.get("name")
        purl_version = package_info.get("version")

        # Create the report content
        report = {
            "id": f"OSSA-{date_str}-{hash(purl_name) % 10000}",
            "version": "1.0.0",
            "severity": package_info.get("severity", []),
            "description": package_info.get("rason", []),
            "title": f"Advisory for {purl_name}",
            "package_name": purl_name,
            "publisher": "Generated by OSSA Collector",
            "last_updated": datetime.now().isoformat(),
            "approvals": [{"consumption": True, "externalization": True}],
            "description": f"Automatically generated OSSA for the package {purl_name}.",
            "purls": [f"pkg:{self.os_type}/{purl_name}@{purl_version}"],
            "regex": [f"^pkg:{self.os_type}/{purl_name}.*"],
            "affected_versions": affected_versions,
            "artifacts": artifacts,
            "licenses": package_info.get("licenses", []),
            "aliases": package_info.get("aliases", []),
            "references": package_info.get("references", [])
        }

        # Save the report to the output directory
        with open(report_path, "w") as f:
            json.dump(report, f, indent=4)
        print(f"Report saved: {report_path}")
